{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Recommendation Engine Models\n",
    "\n",
    "Specify \"Python 3\" Kernel  and \"Data Science\" Image. Set the instance type as ml.t3.medium (default) for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "In this notebook, we'll be building two models: a collaborative filtering model using SageMaker's built-in Factorization Machines and a ranking model leveraging SageMaker's built-in XGBoost.\n",
    "\n",
    "The collaborative filtering model will recommend products based on historical user-product interaction.\n",
    "\n",
    "The ranking model will rerank the recommended products from the collaborative filtering model by taking the user's click-stream activity and using that to make personalized recommendations.\n",
    "\n",
    "We'll put these two models together in order to built a recommendation engine.\n",
    "\n",
    "For example, imagine a user is shopping around on a website and visits a \"hot fudge\" product. We'll want to fetch related items and sort them by the user's recent activity.\n",
    "\n",
    "This notebook should take ~20 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "from utils import *\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import gmtime, strftime, sleep, time\n",
    "from parameter_store import ParameterStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "featurestore_runtime = boto3.client(service_name='sagemaker-featurestore-runtime',\n",
    "                                    region_name=region)\n",
    "ps = ParameterStore(verbose=False)\n",
    "ps.set_namespace('feature-store-workshop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CF model variables\n",
    "prefix = 'recsys'\n",
    "train_key = 'train.protobuf'\n",
    "train_prefix = f'{prefix}/train'\n",
    "test_key = 'test.protobuf'\n",
    "test_prefix = f'{prefix}/test'\n",
    "output_prefix = f's3://{default_bucket}/{prefix}/output'\n",
    "\n",
    "# Other variables used in notebook\n",
    "current_timestamp = strftime('%m-%d-%H-%M', gmtime())\n",
    "query_results= 'sagemaker-recsys-featurestore-workshop'\n",
    "prefix = 'recsys-feature-store'\n",
    "cf_model_endpoint_name = f'recsys-cf-model-{current_timestamp}'\n",
    "ranking_model_endpoint_name = f'recsys-rerank-model-{current_timestamp}'\n",
    "\n",
    "# Add variables to be saved for later notebooks\n",
    "ps.add({'cf_model_endpoint_name': cf_model_endpoint_name,\n",
    "        'ranking_model_endpoint_name': ranking_model_endpoint_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load variables from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ps.read()\n",
    "\n",
    "customers_feature_group_name = parameters['customers_feature_group_name']\n",
    "products_feature_group_name = parameters['products_feature_group_name']\n",
    "orders_feature_group_name = parameters['orders_feature_group_name']\n",
    "click_stream_historical_feature_group_name = parameters['click_stream_historical_feature_group_name']\n",
    "click_stream_feature_group_name = parameters['click_stream_feature_group_name']\n",
    "\n",
    "customers_table = parameters['customers_table']\n",
    "products_table = parameters['products_table']\n",
    "orders_table = parameters['orders_table']\n",
    "click_stream_historical_table = parameters['click_stream_historical_table']\n",
    "click_stream_table = parameters['click_stream_table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Feature Store for Collaborative Filtering model training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our collaborative filtering model, we need data.\n",
    "\n",
    "Now that we have our data in the Feature Store, let's query the offline store (across multiple `FeatureGroups` that we created in the previous notebook) to get the data we'll need to train our collaborative filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select click_stream_customers.customer_id,\n",
    "       products.product_id,\n",
    "       rating,\n",
    "       state,\n",
    "       age,\n",
    "       is_married,\n",
    "       product_name\n",
    "from (\n",
    "    select c.customer_id,\n",
    "           cs.product_id,\n",
    "           cs.bought,\n",
    "           cs.rating,\n",
    "           c.state,\n",
    "           c.age,\n",
    "           c.is_married\n",
    "    from \"{click_stream_historical_table}\" as cs\n",
    "    left join \"{customers_table}\" as c\n",
    "    on cs.customer_id = c.customer_id\n",
    ") click_stream_customers\n",
    "left join\n",
    "(select * from \"{products_table}\") products\n",
    "on click_stream_customers.product_id = products.product_id\n",
    "where click_stream_customers.bought = 1\n",
    "'''\n",
    "\n",
    "df_cf_features, query = query_offline_store(click_stream_feature_group_name, query,\n",
    "                                            sagemaker_session)\n",
    "df_cf_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature store has some metadata columns that can be used to filter out any duplicate (since the offline feature store is versioned) and deleted records (deleted records don't really get deleted. Instead, an `is_deleted` metadata column is turned to `True`).\n",
    "\n",
    "We don't filter for those things here to keep the query a little more readable, but feel free to see examples of this in our [docs](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-athena-glue-integration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data for Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our training data, we need to transform a few variables so that we have a proper input for our model. We'll be using just two types of transformations: one-hot encoding and tf-idf.\n",
    "\n",
    "We have below a couple helper functions to help us with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cf_data(training_df, inference_df=None):\n",
    "    \"\"\"\n",
    "    Transform a pandas DataFrame to prepare for\n",
    "    collabative filtering model input.\n",
    "    \n",
    "    :training_df: pandas.DataFrame\n",
    "    :inference_df: pandas.DataFrame\n",
    "    :return: numpy.ndarray\n",
    "    \"\"\"\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    vectorizer = TfidfVectorizer(min_df=2)\n",
    "    \n",
    "    onehot_cols = ['product_id', 'customer_id', 'is_married',\n",
    "                   'state']\n",
    "    \n",
    "    if inference_df is not None:\n",
    "        enc.fit(training_df[onehot_cols])\n",
    "        onehot_output = enc.transform(inference_df[onehot_cols])\n",
    "        unique_descriptions = training_df['product_name'].unique()\n",
    "        vectorizer.fit(unique_descriptions)\n",
    "        tfidf_output = vectorizer.transform(inference_df['product_name'])\n",
    "    else:\n",
    "        onehot_output = enc.fit_transform(training_df[onehot_cols])\n",
    "        unique_descriptions = training_df['product_name'].unique()\n",
    "        vectorizer.fit(unique_descriptions)\n",
    "        tfidf_output = vectorizer.transform(training_df['product_name'])\n",
    "    \n",
    "    X = hstack([onehot_output, tfidf_output], format='csr', dtype='float32')\n",
    "    return X\n",
    "    \n",
    "def load_dataset(df):\n",
    "    \"\"\"\n",
    "    Transform dataframe and split into features\n",
    "    and target variable\n",
    "    \n",
    "    :param df: pandas.DataFrame\n",
    "    :return: tuple(numpy.ndarray, numpy.ndarray)\n",
    "    \"\"\"\n",
    "    X = transform_cf_data(df)\n",
    "    y = df['rating'].values.astype('float32')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load and transform the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset(df_cf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then split our data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the Factorization Machines model expects our input data to be in RecordIO Format.\n",
    "\n",
    "In the protobuf RecordIO format, SageMaker converts each observation in the dataset into a binary representation as a set of 4-byte floats, then loads it in the protobuf values field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's convert our training data to this RecordIO format and upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_to_protobuf(X, y, bucket, prefix, key):\n",
    "    \"\"\"\n",
    "    Save numpy data as RecordIO format and upload\n",
    "    to S3\n",
    "    \n",
    "    :param X: numpy.ndarray\n",
    "    :param y: numpy.ndarray\n",
    "    :param bucket: str\n",
    "    :param prefix: str\n",
    "    :param key: str\n",
    "    \"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, y)\n",
    "    buf.seek(0)\n",
    "    obj = \"{}/{}\".format(prefix, key)\n",
    "    boto3.resource(\"s3\").Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return \"s3://{}/{}\".format(bucket, obj)\n",
    "\n",
    "train_data_location = write_dataset_to_protobuf(X_train, y_train, default_bucket, train_prefix, train_key)\n",
    "test_data_location = write_dataset_to_protobuf(X_test, y_test, default_bucket, test_prefix, test_key)\n",
    "\n",
    "print(train_data_location)\n",
    "print(test_data_location)\n",
    "print(\"Output: {}\".format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variables to be saved for later notebooks\n",
    "ps.add({'train_data_location': train_data_location,\n",
    "        'test_data_location': test_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Collaborative Filtering model using SageMaker\n",
    "\n",
    "Let's create a collaborative filtering model. A collaborative filering model predicts the interests of a user by looking at the interests of many more users. For example, if you want to recommend an item to user A, you might base it off the interest of a similar user B.\n",
    "\n",
    "For our purposes, we'll be using [Factorization Machines](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html) as our collaborive filtering model which is a general-purpose supervised learning algorithm that you can use for both classification and regression tasks. It's an extension of a linear model that is designed to capture interactions between features within high dimensional sparse datasets economically.\n",
    "\n",
    "Essentially, our collaborative filtering model will recommend products based on historical user-product interaction.\n",
    "\n",
    "<img src=\"./img/collab-inputs.png\" alt=\"collab filtering model inputs\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an Estimator and use Factorization Machines container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\", region=region)\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    output_path=output_prefix,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "# Set our hyperparameters\n",
    "input_dims = X_train.shape[1]\n",
    "fm.set_hyperparameters(\n",
    "    feature_dim=input_dims,\n",
    "    predictor_type=\"regressor\",\n",
    "    mini_batch_size=1000,\n",
    "    num_factors=64,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.fit({'train': train_data_location, 'test': test_data_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = fm.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our model, let's deploy it as a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model_predictor = fm.deploy(\n",
    "    endpoint_name = cf_model_endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=FMSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Feature Store for Ranking model training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our collaborative filtering model, let's now move on to training our ranking model.\n",
    "\n",
    "First, let's query the offline feature store (across multiple `FeatureGroups`) to get the data we'll need to train our ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select bought,\n",
    "       healthy_activity_last_2m,\n",
    "       product_health_index,\n",
    "       customer_health_index,\n",
    "       product_category\n",
    "from (\n",
    "    select c.customer_health_index,\n",
    "           cs.product_id,\n",
    "           cs.healthy_activity_last_2m,\n",
    "           cs.bought\n",
    "    from \"{click_stream_historical_table}\" as cs\n",
    "    left join \"{customers_table}\" as c\n",
    "    on cs.customer_id = c.customer_id\n",
    ") click_stream_customers\n",
    "left join\n",
    "(select * from \"{products_table}\") products\n",
    "on click_stream_customers.product_id = products.product_id\n",
    "'''\n",
    "\n",
    "df_rank_features, query = query_offline_store(click_stream_feature_group_name, query,\n",
    "                                              sagemaker_session)\n",
    "df_rank_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature store has some metadata columns that can be used to filter out any duplicates (since the offline feature store is versioned) and deleted records (deleted records don't really get deleted by an `is_deleted` column is turned to `True`). We don't do that here to keep the query a little more readable, but feel free to see examples of this in our [docs](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-athena-glue-integration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data for Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only transformation we'll need to do for our ranking model data is onehot-encode the product categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_features = pd.concat([df_rank_features, pd.get_dummies(df_rank_features['product_category'], prefix='prod_cat')], axis=1)\n",
    "del df_rank_features['product_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split our data into training and validation sets and save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, _ = np.split(df_rank_features.sample(frac=1, random_state=1729), [int(0.7 * len(df_rank_features)), int(0.9 * len(df_rank_features))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload those datasets to S3 and prepare our training and validation inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(default_bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(default_bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train/train.csv'.format(default_bucket, prefix), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/validation.csv'.format(default_bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ranking model will be an XGBoost model. It will rerank the recommended products from the collaborative filtering model by taking the user's click-stream activity and using that to make personalized recommendations.\n",
    "\n",
    "<img src=\"./img/ranking-inputs.png\" alt=\"Ranking model inputs\" style=\"width: 500px;\"/>\n",
    "\n",
    "We'll be predicting `bought` which is a boolean variable that indicates whether a user bought an item or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', region, version='1.2-2')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(default_bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker_session)\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth= 5,\n",
    "    eta= 0.2,\n",
    "    gamma= 4,\n",
    "    min_child_weight= 6,\n",
    "    subsample= 0.7,\n",
    "    objective= 'binary:logistic',\n",
    "    num_round= 50,\n",
    "    verbosity= 2\n",
    ")\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our ranking model, let's deploy it as a real-time endpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(\n",
    "    endpoint_name = ranking_model_endpoint_name,\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.m4.xlarge',\n",
    "    serializer = CSVSerializer(),\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CF inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_rated_products_by_customer_state(customer_id, top_n):\n",
    "    # Sample some records to be used for inference\n",
    "    # Sample by top rated products in State\n",
    "    record = featurestore_runtime.get_record(FeatureGroupName=customers_feature_group_name,\n",
    "                                             RecordIdentifierValueAsString=customer_id,\n",
    "                                             FeatureNames=['state', 'is_married', 'age'])\n",
    "    # Parse through record features\n",
    "    other_customer_features = {}\n",
    "    for feature in record['Record']:\n",
    "        other_customer_features[feature['FeatureName']] = feature['ValueAsString']\n",
    "        \n",
    "    # Get state\n",
    "    state = other_customer_features['state']\n",
    "    # Filter DF by state\n",
    "    df_cf_features_by_state = df_cf_features[df_cf_features['state'] == state]\n",
    "    \n",
    "    # Get top rated products by customer's state\n",
    "    popular_items = df_cf_features_by_state.groupby([\"product_id\", \"product_name\"])['rating'].agg('mean').sort_values(ascending=False).reset_index()\n",
    "    for k, v in other_customer_features.items():\n",
    "        popular_items[k] = v\n",
    "    popular_items['customer_id'] = customer_id\n",
    "    top_n_popular_items = popular_items.iloc[0:top_n]\n",
    "    top_n_popular_items = top_n_popular_items[df_cf_features.columns]\n",
    "    del top_n_popular_items['rating']\n",
    "    return top_n_popular_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the cold-start problem (if a customer has yet to purchase any items), we'll fetch the top-rated products in a given customer's state. We'll then transform this data (like we did with the collaborative filtering model's training data), and use it at the time of inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = 'C3571'\n",
    "cf_inference_df = top_rated_products_by_customer_state(customer_id, 15)\n",
    "cf_inference_payload = transform_cf_data(df_cf_features, cf_inference_df).toarray()\n",
    "\n",
    "ps.add({'inference_customer_id': customer_id})\n",
    "\n",
    "# Save cf_inference_payload for next notebook\n",
    "%store cf_inference_payload\n",
    "%store cf_inference_df\n",
    "ps.store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to Workshop Studio and click on \"Next\"."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "fea7262dfaa662dc7ea8f1b256cf975fd886d2f868152164ef15877318a1e322"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
