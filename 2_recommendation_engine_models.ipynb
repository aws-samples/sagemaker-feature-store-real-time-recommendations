{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Recommendation Engine Models\n",
    "\n",
    "Specify \"Python 3\" Kernel  and \"Data Science\" Image. Set the instance type as ml.t3.medium (default) for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "In this notebook, we'll be building two models: a collaborative filtering model using SageMaker's built-in Factorization Machines and a ranking model leveraging SageMaker's built-in XGBoost.\n",
    "\n",
    "The collaborative filtering model will recommend products based on historical user-product interaction.\n",
    "\n",
    "The ranking model will rerank the recommended products from the collaborative filtering model by taking the user's click-stream activity and using that to make personalized recommendations.\n",
    "\n",
    "We'll put these two models together in order to built a recommendation engine.\n",
    "\n",
    "For example, imagine a user is shopping around on a website and visits a \"hot fudge\" product. We'll want to fetch related items and sort them by the user's recent activity.\n",
    "\n",
    "This notebook should take ~20 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "from utils import *\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import gmtime, strftime, sleep, time\n",
    "from parameter_store import ParameterStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "featurestore_runtime = boto3.client(service_name='sagemaker-featurestore-runtime',\n",
    "                                    region_name=region)\n",
    "ps = ParameterStore(verbose=False)\n",
    "ps.set_namespace('feature-store-workshop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CF model variables\n",
    "prefix = 'recsys'\n",
    "train_key = 'train.protobuf'\n",
    "train_prefix = f'{prefix}/train'\n",
    "test_key = 'test.protobuf'\n",
    "test_prefix = f'{prefix}/test'\n",
    "output_prefix = f's3://{default_bucket}/{prefix}/output'\n",
    "\n",
    "# Other variables used in notebook\n",
    "current_timestamp = strftime('%m-%d-%H-%M', gmtime())\n",
    "query_results= 'sagemaker-recsys-featurestore-workshop'\n",
    "prefix = 'recsys-feature-store'\n",
    "cf_model_endpoint_name = f'recsys-cf-model-{current_timestamp}'\n",
    "ranking_model_endpoint_name = f'recsys-rerank-model-{current_timestamp}'\n",
    "\n",
    "# Add variables to be saved for later notebooks\n",
    "ps.add({'cf_model_endpoint_name': cf_model_endpoint_name,\n",
    "        'ranking_model_endpoint_name': ranking_model_endpoint_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load variables from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = ps.read()\n",
    "\n",
    "customers_feature_group_name = parameters['customers_feature_group_name']\n",
    "products_feature_group_name = parameters['products_feature_group_name']\n",
    "orders_feature_group_name = parameters['orders_feature_group_name']\n",
    "click_stream_historical_feature_group_name = parameters['click_stream_historical_feature_group_name']\n",
    "click_stream_feature_group_name = parameters['click_stream_feature_group_name']\n",
    "\n",
    "customers_feature_group = FeatureGroup(\n",
    "    name=customers_feature_group_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "products_feature_group = FeatureGroup(\n",
    "    name=products_feature_group_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "orders_feature_group = FeatureGroup(\n",
    "    name=orders_feature_group_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "click_stream_historical_feature_group = FeatureGroup(\n",
    "    name=click_stream_historical_feature_group_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "click_stream_feature_group = FeatureGroup(\n",
    "    name=click_stream_feature_group_name, sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureGroup recsys-customers-fg-05-29-00-10 successfully created.\n",
      "FeatureGroup recsys-products-fg-05-29-00-10 successfully created.\n",
      "FeatureGroup recsys-orders-fg-05-29-00-10 successfully created.\n",
      "FeatureGroup recsys-click-stream-historical-fg-05-29-00-10 successfully created.\n",
      "FeatureGroup recsys-click-stream-fg-05-29-00-10 successfully created.\n"
     ]
    }
   ],
   "source": [
    "# df_click_stream_historical_data.head()\n",
    "def check_feature_group_status(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group to be Created\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "    \n",
    "    \n",
    "check_feature_group_status(customers_feature_group)\n",
    "check_feature_group_status(products_feature_group)\n",
    "check_feature_group_status(orders_feature_group)\n",
    "check_feature_group_status(click_stream_historical_feature_group)\n",
    "check_feature_group_status(click_stream_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Feature Store for Collaborative Filtering model training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our collaborative filtering model, we need data.\n",
    "\n",
    "Now that we have our data in the Feature Store, let's query the offline store (across multiple `FeatureGroups` that we created in the previous notebook) to get the data we'll need to train our collaborative filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>state</th>\n",
       "      <th>age</th>\n",
       "      <th>is_married</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2786</td>\n",
       "      <td>P1206</td>\n",
       "      <td>1.199858</td>\n",
       "      <td>new mexico</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>creamy caramel filled hard candies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C866</td>\n",
       "      <td>P1206</td>\n",
       "      <td>1.424285</td>\n",
       "      <td>delaware</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>creamy caramel filled hard candies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C2786</td>\n",
       "      <td>P14984</td>\n",
       "      <td>2.513348</td>\n",
       "      <td>new mexico</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1 apple + 1 mango fruit bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4053</td>\n",
       "      <td>P992</td>\n",
       "      <td>2.855658</td>\n",
       "      <td>louisiana</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>outshine simply yogurt bars strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C4913</td>\n",
       "      <td>P14341</td>\n",
       "      <td>2.773447</td>\n",
       "      <td>north carolina</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>vegetarian chili seasoning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id product_id    rating           state  age  is_married  \\\n",
       "0       C2786      P1206  1.199858      new mexico   75           0   \n",
       "1        C866      P1206  1.424285        delaware   35           1   \n",
       "2       C2786     P14984  2.513348      new mexico   75           0   \n",
       "3       C4053       P992  2.855658       louisiana   24           1   \n",
       "4       C4913     P14341  2.773447  north carolina   28           0   \n",
       "\n",
       "                             product_name  \n",
       "0      creamy caramel filled hard candies  \n",
       "1      creamy caramel filled hard candies  \n",
       "2             1 apple + 1 mango fruit bar  \n",
       "3  outshine simply yogurt bars strawberry  \n",
       "4              vegetarian chili seasoning  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_stream_query = click_stream_historical_feature_group.athena_query()\n",
    "click_stream_historical_table = click_stream_query.table_name\n",
    "\n",
    "customers_query = customers_feature_group.athena_query()\n",
    "customers_table = customers_query.table_name\n",
    "\n",
    "products_query = products_feature_group.athena_query()\n",
    "products_table = products_query.table_name\n",
    "\n",
    "\n",
    "query = f'''\n",
    "select click_stream_customers.customer_id,\n",
    "       products.product_id,\n",
    "       rating,\n",
    "       state,\n",
    "       age,\n",
    "       is_married,\n",
    "       product_name\n",
    "from (\n",
    "    select c.customer_id,\n",
    "           cs.product_id,\n",
    "           cs.bought,\n",
    "           cs.rating,\n",
    "           c.state,\n",
    "           c.age,\n",
    "           c.is_married\n",
    "    from \"{click_stream_historical_table}\" as cs\n",
    "    left join \"{customers_table}\" as c\n",
    "    on cs.customer_id = c.customer_id\n",
    ") click_stream_customers\n",
    "left join\n",
    "(select * from \"{products_table}\") products\n",
    "on click_stream_customers.product_id = products.product_id\n",
    "where click_stream_customers.bought = 1\n",
    "'''\n",
    "\n",
    "df_cf_features = pd.DataFrame()\n",
    "click_stream_query.run(query_string=query, output_location='s3://'+default_bucket+'/query_results/')\n",
    "click_stream_query.wait()\n",
    "df_cf_features = click_stream_query.as_dataframe()\n",
    "df_cf_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature store has some metadata columns that can be used to filter out any duplicate (since the offline feature store is versioned) and deleted records (deleted records don't really get deleted. Instead, an `is_deleted` metadata column is turned to `True`).\n",
    "\n",
    "We don't filter for those things here to keep the query a little more readable, but feel free to see examples of this in our [docs](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-athena-glue-integration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data for Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our training data, we need to transform a few variables so that we have a proper input for our model. We'll be using just two types of transformations: one-hot encoding and tf-idf.\n",
    "\n",
    "We have below a couple helper functions to help us with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_cf_data(training_df, inference_df=None):\n",
    "    \"\"\"\n",
    "    Transform a pandas DataFrame to prepare for\n",
    "    collabative filtering model input.\n",
    "    \n",
    "    :training_df: pandas.DataFrame\n",
    "    :inference_df: pandas.DataFrame\n",
    "    :return: numpy.ndarray\n",
    "    \"\"\"\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    vectorizer = TfidfVectorizer(min_df=2)\n",
    "    \n",
    "    onehot_cols = ['product_id', 'customer_id', 'is_married',\n",
    "                   'state']\n",
    "    \n",
    "    if inference_df is not None:\n",
    "        enc.fit(training_df[onehot_cols])\n",
    "        onehot_output = enc.transform(inference_df[onehot_cols])\n",
    "        unique_descriptions = training_df['product_name'].unique()\n",
    "        vectorizer.fit(unique_descriptions)\n",
    "        tfidf_output = vectorizer.transform(inference_df['product_name'])\n",
    "    else:\n",
    "        onehot_output = enc.fit_transform(training_df[onehot_cols])\n",
    "        unique_descriptions = training_df['product_name'].unique()\n",
    "        vectorizer.fit(unique_descriptions)\n",
    "        tfidf_output = vectorizer.transform(training_df['product_name'])\n",
    "    \n",
    "    X = hstack([onehot_output, tfidf_output], format='csr', dtype='float32')\n",
    "    return X\n",
    "    \n",
    "def load_dataset(df):\n",
    "    \"\"\"\n",
    "    Transform dataframe and split into features\n",
    "    and target variable\n",
    "    \n",
    "    :param df: pandas.DataFrame\n",
    "    :return: tuple(numpy.ndarray, numpy.ndarray)\n",
    "    \"\"\"\n",
    "    X = transform_cf_data(df)\n",
    "    y = df['rating'].values.astype('float32')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load and transform the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = load_dataset(df_cf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then split our data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65393, 28366) (16349, 28366) (65393,) (16349,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the Factorization Machines model expects our input data to be in RecordIO Format.\n",
    "\n",
    "In the protobuf RecordIO format, SageMaker converts each observation in the dataset into a binary representation as a set of 4-byte floats, then loads it in the protobuf values field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's convert our training data to this RecordIO format and upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-2-XXXXXXXXXXXX/recsys/train/train.protobuf\n",
      "s3://sagemaker-ap-southeast-2-XXXXXXXXXXXX/recsys/test/test.protobuf\n",
      "Output: s3://sagemaker-ap-southeast-2-XXXXXXXXXXXX/recsys/output\n"
     ]
    }
   ],
   "source": [
    "def write_dataset_to_protobuf(X, y, bucket, prefix, key):\n",
    "    \"\"\"\n",
    "    Save numpy data as RecordIO format and upload\n",
    "    to S3\n",
    "    \n",
    "    :param X: numpy.ndarray\n",
    "    :param y: numpy.ndarray\n",
    "    :param bucket: str\n",
    "    :param prefix: str\n",
    "    :param key: str\n",
    "    \"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, y)\n",
    "    buf.seek(0)\n",
    "    obj = \"{}/{}\".format(prefix, key)\n",
    "    boto3.resource(\"s3\").Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return \"s3://{}/{}\".format(bucket, obj)\n",
    "\n",
    "train_data_location = write_dataset_to_protobuf(X_train, y_train, default_bucket, train_prefix, train_key)\n",
    "test_data_location = write_dataset_to_protobuf(X_test, y_test, default_bucket, test_prefix, test_key)\n",
    "\n",
    "print(train_data_location)\n",
    "print(test_data_location)\n",
    "print(\"Output: {}\".format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add variables to be saved for later notebooks\n",
    "ps.add({'train_data_location': train_data_location,\n",
    "        'test_data_location': test_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Collaborative Filtering model using SageMaker\n",
    "\n",
    "Let's create a collaborative filtering model. A collaborative filering model predicts the interests of a user by looking at the interests of many more users. For example, if you want to recommend an item to user A, you might base it off the interest of a similar user B.\n",
    "\n",
    "For our purposes, we'll be using [Factorization Machines](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html) as our collaborive filtering model which is a general-purpose supervised learning algorithm that you can use for both classification and regression tasks. It's an extension of a linear model that is designed to capture interactions between features within high dimensional sparse datasets economically.\n",
    "\n",
    "Essentially, our collaborative filtering model will recommend products based on historical user-product interaction.\n",
    "\n",
    "<img src=\"./img/collab-inputs.png\" alt=\"collab filtering model inputs\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an Estimator and use Factorization Machines container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\", region=region)\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    output_path=output_prefix,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "# Set our hyperparameters\n",
    "input_dims = X_train.shape[1]\n",
    "fm.set_hyperparameters(\n",
    "    feature_dim=input_dims,\n",
    "    predictor_type=\"regressor\",\n",
    "    mini_batch_size=1000,\n",
    "    num_factors=64,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: factorization-machines-2024-05-29-00-35-05-125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:35:05 Starting - Starting the training job...\n",
      "2024-05-29 00:35:21 Starting - Preparing the instances for training...\n",
      "2024-05-29 00:35:58 Downloading - Downloading the training image.....................\n",
      "2024-05-29 00:39:24 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '20', 'feature_dim': '28366', 'mini_batch_size': '1000', 'num_factors': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] Final configuration: {'epochs': '20', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '28366', 'num_factors': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 WARNING 140627447908160] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 6 is a worker.\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:33.034] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:33.037] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 8, \"num_examples\": 1, \"num_bytes\": 111048}\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943173.0295057, \"EndTime\": 1716943173.070657, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 33.90049934387207, \"count\": 1, \"min\": 33.90049934387207, \"max\": 33.90049934387207}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943173.0707624, \"EndTime\": 1716943173.070795, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[00:39:33] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[00:39:33] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[00:39:33] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=2.3243699793236985\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=5.40269580078125\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=2.219640380859375\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:33.930] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 769, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.04838653056041\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=0, train mse <loss>=1.0991143174604936\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=0.8338966582327179\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943173.0707183, \"EndTime\": 1716943173.931281, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"update.time\": {\"sum\": 860.2795600891113, \"count\": 1, \"min\": 860.2795600891113, \"max\": 860.2795600891113}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943173.0709755, \"EndTime\": 1716943173.9314995, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 66393.0, \"count\": 1, \"min\": 66393, \"max\": 66393}, \"Total Batches Seen\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=75985.0648132552 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=0.699270533173287\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=0.4889792785644531\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:33 INFO 140627447908160] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.5935192260742187\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:34.948] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 1015, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=0.7150839339986994\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #quality_metric: host=algo-1, epoch=1, train mse <loss>=0.5113450326630563\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.6103684655391809\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943173.9313607, \"EndTime\": 1716943174.9494588, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1017.7371501922607, \"count\": 1, \"min\": 1017.7371501922607, \"max\": 1017.7371501922607}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943173.9316964, \"EndTime\": 1716943174.949821, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 131786.0, \"count\": 1, \"min\": 131786, \"max\": 131786}, \"Total Batches Seen\": {\"sum\": 133.0, \"count\": 1, \"min\": 133, \"max\": 133}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=64222.65226103779 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=0.6905555103261409\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=0.4768669128417969\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:34 INFO 140627447908160] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.586952880859375\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:35.908] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 952, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=0.7090962377316878\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #quality_metric: host=algo-1, epoch=2, train mse <loss>=0.5028174743652344\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.6054784185236151\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943174.949536, \"EndTime\": 1716943175.9089746, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.7352275848389, \"count\": 1, \"min\": 958.7352275848389, \"max\": 958.7352275848389}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943174.950213, \"EndTime\": 1716943175.9092712, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 197179.0, \"count\": 1, \"min\": 197179, \"max\": 197179}, \"Total Batches Seen\": {\"sum\": 199.0, \"count\": 1, \"min\": 199, \"max\": 199}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=68177.25548425746 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=0.6858606609154707\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=0.47040484619140627\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:35 INFO 140627447908160] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.5828222045898438\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:36.728] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 817, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=0.7023911057760747\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #quality_metric: host=algo-1, epoch=3, train mse <loss>=0.4933532654733369\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.5996325369170218\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943175.9090288, \"EndTime\": 1716943176.729298, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 819.7922706604004, \"count\": 1, \"min\": 819.7922706604004, \"max\": 819.7922706604004}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943175.9094827, \"EndTime\": 1716943176.7295601, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 262572.0, \"count\": 1, \"min\": 262572, \"max\": 262572}, \"Total Batches Seen\": {\"sum\": 265.0, \"count\": 1, \"min\": 265, \"max\": 265}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=79730.76046829497 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=0.679621180313319\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=0.46188494873046876\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:36 INFO 140627447908160] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.5771847534179687\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:37.503] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 771, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=0.6938342617224935\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #quality_metric: host=algo-1, epoch=4, train mse <loss>=0.48140598273999763\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.5921244959975734\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943176.7293534, \"EndTime\": 1716943177.5039217, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.1501331329346, \"count\": 1, \"min\": 774.1501331329346, \"max\": 774.1501331329346}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943176.729749, \"EndTime\": 1716943177.504056, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 327965.0, \"count\": 1, \"min\": 327965, \"max\": 327965}, \"Total Batches Seen\": {\"sum\": 331.0, \"count\": 1, \"min\": 331, \"max\": 331}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=84444.792460138 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=0.6723749729489096\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=0.45208810424804685\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:37 INFO 140627447908160] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.5705239868164063\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:38.292] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 783, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=0.6841473968757971\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #quality_metric: host=algo-1, epoch=5, train mse <loss>=0.46805766065192944\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.5835006454930161\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943177.5039735, \"EndTime\": 1716943178.293152, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.9235019683838, \"count\": 1, \"min\": 788.9235019683838, \"max\": 788.9235019683838}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943177.5042048, \"EndTime\": 1716943178.293383, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 393358.0, \"count\": 1, \"min\": 393358, \"max\": 393358}, \"Total Batches Seen\": {\"sum\": 397.0, \"count\": 1, \"min\": 397, \"max\": 397}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=82852.19188322074 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=0.664622994159271\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=0.4417237243652344\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:38 INFO 140627447908160] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.5635284423828125\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:39.068] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 770, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=0.6739215477205758\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=6, train mse <loss>=0.45417025248209636\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.5742900714296283\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943178.2932088, \"EndTime\": 1716943179.069036, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.421142578125, \"count\": 1, \"min\": 775.421142578125, \"max\": 775.421142578125}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943178.2935927, \"EndTime\": 1716943179.069173, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 458751.0, \"count\": 1, \"min\": 458751, \"max\": 458751}, \"Total Batches Seen\": {\"sum\": 463.0, \"count\": 1, \"min\": 463, \"max\": 463}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=84306.73052890941 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=0.6566801510635001\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=0.43122882080078123\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.5564387817382812\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:39.834] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 763, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=0.6635769646690042\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=7, train mse <loss>=0.44033438803932884\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.564879950321082\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943179.0690897, \"EndTime\": 1716943179.8349438, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 765.5997276306152, \"count\": 1, \"min\": 765.5997276306152, \"max\": 765.5997276306152}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943179.0693188, \"EndTime\": 1716943179.8351235, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 524144.0, \"count\": 1, \"min\": 524144, \"max\": 524144}, \"Total Batches Seen\": {\"sum\": 529.0, \"count\": 1, \"min\": 529, \"max\": 529}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=85380.07795078939 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=0.6487400461363069\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=0.4208636474609375\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:39 INFO 140627447908160] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.5494663696289063\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:40.590] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 753, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=0.6534163943720617\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #quality_metric: host=algo-1, epoch=8, train mse <loss>=0.4269529844341856\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.5555228363961885\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943179.835001, \"EndTime\": 1716943180.591622, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 756.2096118927002, \"count\": 1, \"min\": 756.2096118927002, \"max\": 756.2096118927002}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943179.8353837, \"EndTime\": 1716943180.591916, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 589537.0, \"count\": 1, \"min\": 589537, \"max\": 589537}, \"Total Batches Seen\": {\"sum\": 595.0, \"count\": 1, \"min\": 595, \"max\": 595}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=86422.05922478618 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=0.6409521363668906\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=0.41081964111328123\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:40 INFO 140627447908160] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.5427968139648438\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:41.368] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 771, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=0.6436583883131721\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #quality_metric: host=algo-1, epoch=9, train mse <loss>=0.4142961208459103\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.5464532059178208\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943180.5917187, \"EndTime\": 1716943181.3686094, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.268482208252, \"count\": 1, \"min\": 776.268482208252, \"max\": 776.268482208252}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943180.592315, \"EndTime\": 1716943181.3688226, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 654930.0, \"count\": 1, \"min\": 654930, \"max\": 654930}, \"Total Batches Seen\": {\"sum\": 661.0, \"count\": 1, \"min\": 661, \"max\": 661}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=84197.7997148159 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=0.6334473089090067\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=0.4012554931640625\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:41 INFO 140627447908160] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.5361207885742187\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:42.121] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 749, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=0.6344510547758051\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=10, train mse <loss>=0.40252814090613165\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.5378079723011364\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943181.3686695, \"EndTime\": 1716943182.1223965, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 753.2670497894287, \"count\": 1, \"min\": 753.2670497894287, \"max\": 753.2670497894287}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943181.3691046, \"EndTime\": 1716943182.1225317, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 720323.0, \"count\": 1, \"min\": 720323, \"max\": 720323}, \"Total Batches Seen\": {\"sum\": 727.0, \"count\": 1, \"min\": 727, \"max\": 727}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=86780.1220245459 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=0.6263321496378115\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=0.39229196166992186\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.5296707763671875\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:42.936] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 812, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=0.6258821093660648\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=11, train mse <loss>=0.3917284148245147\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.5296877159349846\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943182.1224484, \"EndTime\": 1716943182.9367995, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.0368461608887, \"count\": 1, \"min\": 814.0368461608887, \"max\": 814.0368461608887}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943182.1227415, \"EndTime\": 1716943182.9370315, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 785716.0, \"count\": 1, \"min\": 785716, \"max\": 785716}, \"Total Batches Seen\": {\"sum\": 793.0, \"count\": 1, \"min\": 793, \"max\": 793}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=80297.43202556841 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=0.6196789851832434\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=0.38400204467773436\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:42 INFO 140627447908160] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.5234930419921875\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:43.692] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 753, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=0.6179902861519048\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #quality_metric: host=algo-1, epoch=12, train mse <loss>=0.3819119937781132\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.5221529467033618\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943182.93689, \"EndTime\": 1716943183.692754, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 755.4678916931152, \"count\": 1, \"min\": 755.4678916931152, \"max\": 755.4678916931152}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943182.9372606, \"EndTime\": 1716943183.6929443, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 851109.0, \"count\": 1, \"min\": 851109, \"max\": 851109}, \"Total Batches Seen\": {\"sum\": 859.0, \"count\": 1, \"min\": 859, \"max\": 859}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=86523.25777123167 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.613523563793664\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=0.3764111633300781\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:43 INFO 140627447908160] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.5177263793945313\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:44.538] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 840, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=0.610777409585509\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #quality_metric: host=algo-1, epoch=13, train mse <loss>=0.3730490440599846\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.5152088220769708\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943183.6928098, \"EndTime\": 1716943184.538854, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 845.649242401123, \"count\": 1, \"min\": 845.649242401123, \"max\": 845.649242401123}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943183.6931825, \"EndTime\": 1716943184.5389938, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 916502.0, \"count\": 1, \"min\": 916502, \"max\": 916502}, \"Total Batches Seen\": {\"sum\": 925.0, \"count\": 1, \"min\": 925, \"max\": 925}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=77306.3238888831 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.6078711662320628\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=0.3695073547363281\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:44 INFO 140627447908160] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.5121652221679688\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:45.430] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 890, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=0.6042197229573179\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #quality_metric: host=algo-1, epoch=14, train mse <loss>=0.3650814736106179\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.5088311596494732\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943184.5389092, \"EndTime\": 1716943185.4312375, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 892.073392868042, \"count\": 1, \"min\": 892.073392868042, \"max\": 892.073392868042}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943184.5391417, \"EndTime\": 1716943185.4313726, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 981895.0, \"count\": 1, \"min\": 981895, \"max\": 981895}, \"Total Batches Seen\": {\"sum\": 991.0, \"count\": 1, \"min\": 991, \"max\": 991}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=73285.19445424894 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.6027058179398268\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=0.36325430297851563\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:45 INFO 140627447908160] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.5068946533203125\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:46.285] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 849, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=0.598277434069688\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #quality_metric: host=algo-1, epoch=15, train mse <loss>=0.35793588811700994\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.5029859531286991\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943185.4312897, \"EndTime\": 1716943186.2860541, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 854.485034942627, \"count\": 1, \"min\": 854.485034942627, \"max\": 854.485034942627}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943185.4315462, \"EndTime\": 1716943186.2862678, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1047288.0, \"count\": 1, \"min\": 1047288, \"max\": 1047288}, \"Total Batches Seen\": {\"sum\": 1057.0, \"count\": 1, \"min\": 1057, \"max\": 1057}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=76500.53174537209 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.597998982610443\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=0.357602783203125\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:46 INFO 140627447908160] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.5020321655273438\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:47.030] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 742, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=0.5929021012345286\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=16, train mse <loss>=0.35153290164831913\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.4976553497314453\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943186.2861469, \"EndTime\": 1716943187.031127, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 744.6818351745605, \"count\": 1, \"min\": 744.6818351745605, \"max\": 744.6818351745605}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943186.2864232, \"EndTime\": 1716943187.031272, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1112681.0, \"count\": 1, \"min\": 1112681, \"max\": 1112681}, \"Total Batches Seen\": {\"sum\": 1123.0, \"count\": 1, \"min\": 1123, \"max\": 1123}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=87784.25226271317 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.5937158707296362\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=0.35249853515625\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.49739056396484377\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:47.781] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 748, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=0.5880419338814606\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=17, train mse <loss>=0.3457933160030481\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.49279525710597183\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943187.031182, \"EndTime\": 1716943187.7815292, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 750.0548362731934, \"count\": 1, \"min\": 750.0548362731934, \"max\": 750.0548362731934}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943187.0314512, \"EndTime\": 1716943187.7816916, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1178074.0, \"count\": 1, \"min\": 1178074, \"max\": 1178074}, \"Total Batches Seen\": {\"sum\": 1189.0, \"count\": 1, \"min\": 1189, \"max\": 1189}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=87153.18146307641 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.5898197946294433\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=0.34788739013671877\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:47 INFO 140627447908160] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.49295233154296875\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:48.601] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 817, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=0.5836454162716652\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #quality_metric: host=algo-1, epoch=18, train mse <loss>=0.3406419719349254\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.4883592219497218\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943187.7815838, \"EndTime\": 1716943188.6016605, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 819.7531700134277, \"count\": 1, \"min\": 819.7531700134277, \"max\": 819.7531700134277}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943187.7818813, \"EndTime\": 1716943188.6018543, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1243467.0, \"count\": 1, \"min\": 1243467, \"max\": 1243467}, \"Total Batches Seen\": {\"sum\": 1255.0, \"count\": 1, \"min\": 1255, \"max\": 1255}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=79740.61198809523 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.5862745645090143\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=0.3437178649902344\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:48 INFO 140627447908160] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.48873703002929686\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:49.379] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 775, \"num_examples\": 66, \"num_bytes\": 7310464}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=0.5796635500736886\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, epoch=19, train mse <loss>=0.3360098312840317\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.4843095837217389\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, train rmse <loss>=0.5796635500736886\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, train mse <loss>=0.3360098312840317\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, train absolute_loss <loss>=0.4843095837217389\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943188.6017206, \"EndTime\": 1716943189.3805523, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 778.4221172332764, \"count\": 1, \"min\": 778.4221172332764, \"max\": 778.4221172332764}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943188.6021047, \"EndTime\": 1716943189.3807492, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1308860.0, \"count\": 1, \"min\": 1308860, \"max\": 1308860}, \"Total Batches Seen\": {\"sum\": 1321.0, \"count\": 1, \"min\": 1321, \"max\": 1321}, \"Max Records Seen Between Resets\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Max Batches Seen Between Resets\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 65393.0, \"count\": 1, \"min\": 65393, \"max\": 65393}, \"Number of Batches Since Last Reset\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #throughput_metric: host=algo-1, train throughput=83971.73006032793 records/second\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 WARNING 140627447908160] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943189.380624, \"EndTime\": 1716943189.386687, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 5.669116973876953, \"count\": 1, \"min\": 5.669116973876953, \"max\": 5.669116973876953}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] Saved checkpoint to \"/tmp/tmpvigxala1/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:49.419] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 16385, \"num_examples\": 1, \"num_bytes\": 111960}\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:39:49.532] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 112, \"num_examples\": 17, \"num_bytes\": 1828592}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943189.4191773, \"EndTime\": 1716943189.532194, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16349.0, \"count\": 1, \"min\": 16349, \"max\": 16349}, \"Total Batches Seen\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Max Records Seen Between Resets\": {\"sum\": 16349.0, \"count\": 1, \"min\": 16349, \"max\": 16349}, \"Max Batches Seen Between Resets\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 16349.0, \"count\": 1, \"min\": 16349, \"max\": 16349}, \"Number of Batches Since Last Reset\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}}}\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #test_score (algo-1) : ('rmse', 0.7654671821101969)\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #test_score (algo-1) : ('mse', 0.5859400068877254)\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #test_score (algo-1) : ('absolute_loss', 0.6434210347315538)\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, test rmse <loss>=0.7654671821101969\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, test mse <loss>=0.5859400068877254\u001b[0m\n",
      "\u001b[34m[05/29/2024 00:39:49 INFO 140627447908160] #quality_metric: host=algo-1, test absolute_loss <loss>=0.6434210347315538\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716943189.3869832, \"EndTime\": 1716943189.532878, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 13.551473617553711, \"count\": 1, \"min\": 13.551473617553711, \"max\": 13.551473617553711}, \"totaltime\": {\"sum\": 16519.063711166382, \"count\": 1, \"min\": 16519.063711166382, \"max\": 16519.063711166382}}}\u001b[0m\n",
      "\n",
      "2024-05-29 00:40:03 Uploading - Uploading generated training model\n",
      "2024-05-29 00:40:03 Completed - Training job completed\n",
      "Training seconds: 259\n",
      "Billable seconds: 259\n"
     ]
    }
   ],
   "source": [
    "fm.fit({'train': train_data_location, 'test': test_data_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = fm.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our model, let's deploy it as a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: factorization-machines-2024-05-29-00-40-17-951\n",
      "INFO:sagemaker:Creating endpoint-config with name recsys-cf-model-05-29-00-34\n",
      "INFO:sagemaker:Creating endpoint with name recsys-cf-model-05-29-00-34\n"
     ]
    }
   ],
   "source": [
    "cf_model_predictor = fm.deploy(\n",
    "    endpoint_name = cf_model_endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=FMSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recsys-cf-model-05-29-00-34'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_model_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Feature Store for Ranking model training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our collaborative filtering model, let's now move on to training our ranking model.\n",
    "\n",
    "First, let's query the offline feature store (across multiple `FeatureGroups`) to get the data we'll need to train our ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query 3839da01-c1b9-45c3-980a-24b1b694198d is being executed.\n",
      "INFO:sagemaker:Query 3839da01-c1b9-45c3-980a-24b1b694198d successfully executed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bought</th>\n",
       "      <th>healthy_activity_last_2m</th>\n",
       "      <th>product_health_index</th>\n",
       "      <th>customer_health_index</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>vitamins_supplements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.099806</td>\n",
       "      <td>energy_granola_bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>packaged_cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.704001</td>\n",
       "      <td>baking_ingredients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>packaged_cheese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bought  healthy_activity_last_2m  product_health_index  \\\n",
       "0       0                         3                   0.9   \n",
       "1       0                         1                   0.9   \n",
       "2       1                         2                   0.3   \n",
       "3       1                         0                   0.3   \n",
       "4       0                        10                   0.3   \n",
       "\n",
       "   customer_health_index      product_category  \n",
       "0               0.250698  vitamins_supplements  \n",
       "1               0.099806   energy_granola_bars  \n",
       "2               0.250698       packaged_cheese  \n",
       "3               0.704001    baking_ingredients  \n",
       "4               0.250698       packaged_cheese  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f'''\n",
    "select bought,\n",
    "       healthy_activity_last_2m,\n",
    "       product_health_index,\n",
    "       customer_health_index,\n",
    "       product_category\n",
    "from (\n",
    "    select c.customer_health_index,\n",
    "           cs.product_id,\n",
    "           cs.healthy_activity_last_2m,\n",
    "           cs.bought\n",
    "    from \"{click_stream_historical_table}\" as cs\n",
    "    left join \"{customers_table}\" as c\n",
    "    on cs.customer_id = c.customer_id\n",
    ") click_stream_customers\n",
    "left join\n",
    "(select * from \"{products_table}\") products\n",
    "on click_stream_customers.product_id = products.product_id\n",
    "'''\n",
    "\n",
    "df_rank_features, query = query_offline_store(click_stream_feature_group_name, query,\n",
    "                                              sagemaker_session)\n",
    "df_rank_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature store has some metadata columns that can be used to filter out any duplicates (since the offline feature store is versioned) and deleted records (deleted records don't really get deleted by an `is_deleted` column is turned to `True`). We don't do that here to keep the query a little more readable, but feel free to see examples of this in our [docs](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-athena-glue-integration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data for Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only transformation we'll need to do for our ranking model data is onehot-encode the product categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_rank_features = pd.concat([df_rank_features, pd.get_dummies(df_rank_features['product_category'], prefix='prod_cat')], axis=1)\n",
    "del df_rank_features['product_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bought</th>\n",
       "      <th>healthy_activity_last_2m</th>\n",
       "      <th>product_health_index</th>\n",
       "      <th>customer_health_index</th>\n",
       "      <th>prod_cat_baby_food_formula</th>\n",
       "      <th>prod_cat_baking_ingredients</th>\n",
       "      <th>prod_cat_candy_chocolate</th>\n",
       "      <th>prod_cat_chips_pretzels</th>\n",
       "      <th>prod_cat_cleaning_products</th>\n",
       "      <th>prod_cat_coffee</th>\n",
       "      <th>...</th>\n",
       "      <th>prod_cat_hair_care</th>\n",
       "      <th>prod_cat_ice_cream_ice</th>\n",
       "      <th>prod_cat_juice_nectars</th>\n",
       "      <th>prod_cat_packaged_cheese</th>\n",
       "      <th>prod_cat_refrigerated</th>\n",
       "      <th>prod_cat_soup_broth_bouillon</th>\n",
       "      <th>prod_cat_spices_seasonings</th>\n",
       "      <th>prod_cat_tea</th>\n",
       "      <th>prod_cat_vitamins_supplements</th>\n",
       "      <th>prod_cat_yogurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.099806</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.704001</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bought  healthy_activity_last_2m  product_health_index  \\\n",
       "0       0                         3                   0.9   \n",
       "1       0                         1                   0.9   \n",
       "2       1                         2                   0.3   \n",
       "3       1                         0                   0.3   \n",
       "4       0                        10                   0.3   \n",
       "\n",
       "   customer_health_index  prod_cat_baby_food_formula  \\\n",
       "0               0.250698                       False   \n",
       "1               0.099806                       False   \n",
       "2               0.250698                       False   \n",
       "3               0.704001                       False   \n",
       "4               0.250698                       False   \n",
       "\n",
       "   prod_cat_baking_ingredients  prod_cat_candy_chocolate  \\\n",
       "0                        False                     False   \n",
       "1                        False                     False   \n",
       "2                        False                     False   \n",
       "3                         True                     False   \n",
       "4                        False                     False   \n",
       "\n",
       "   prod_cat_chips_pretzels  prod_cat_cleaning_products  prod_cat_coffee  ...  \\\n",
       "0                    False                       False            False  ...   \n",
       "1                    False                       False            False  ...   \n",
       "2                    False                       False            False  ...   \n",
       "3                    False                       False            False  ...   \n",
       "4                    False                       False            False  ...   \n",
       "\n",
       "   prod_cat_hair_care  prod_cat_ice_cream_ice  prod_cat_juice_nectars  \\\n",
       "0               False                   False                   False   \n",
       "1               False                   False                   False   \n",
       "2               False                   False                   False   \n",
       "3               False                   False                   False   \n",
       "4               False                   False                   False   \n",
       "\n",
       "   prod_cat_packaged_cheese  prod_cat_refrigerated  \\\n",
       "0                     False                  False   \n",
       "1                     False                  False   \n",
       "2                      True                  False   \n",
       "3                     False                  False   \n",
       "4                      True                  False   \n",
       "\n",
       "   prod_cat_soup_broth_bouillon  prod_cat_spices_seasonings  prod_cat_tea  \\\n",
       "0                         False                       False         False   \n",
       "1                         False                       False         False   \n",
       "2                         False                       False         False   \n",
       "3                         False                       False         False   \n",
       "4                         False                       False         False   \n",
       "\n",
       "   prod_cat_vitamins_supplements  prod_cat_yogurt  \n",
       "0                           True            False  \n",
       "1                          False            False  \n",
       "2                          False            False  \n",
       "3                          False            False  \n",
       "4                          False            False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split our data into training and validation sets and save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data, _ = np.split(df_rank_features.sample(frac=1, random_state=1729), [int(0.7 * len(df_rank_features)), int(0.9 * len(df_rank_features))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload those datasets to S3 and prepare our training and validation inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(default_bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(default_bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train/train.csv'.format(default_bucket, prefix), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/validation.csv'.format(default_bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ranking model will be an XGBoost model. It will rerank the recommended products from the collaborative filtering model by taking the user's click-stream activity and using that to make personalized recommendations.\n",
    "\n",
    "<img src=\"./img/ranking-inputs.png\" alt=\"Ranking model inputs\" style=\"width: 500px;\"/>\n",
    "\n",
    "We'll be predicting `bought` which is a boolean variable that indicates whether a user bought an item or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-05-29-00-40-27-642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:40:27 Starting - Starting the training job...\n",
      "2024-05-29 00:40:43 Starting - Preparing the instances for training...\n",
      "2024-05-29 00:41:13 Downloading - Downloading input data...\n",
      "2024-05-29 00:41:33 Downloading - Downloading the training image......\n",
      "2024-05-29 00:42:34 Training - Training image download completed. Training in progress..\u001b[34m[2024-05-29 00:42:51.157 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Train matrix has 139965 rows and 23 columns\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Validation matrix has 39990 rows\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:42:51.475 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:42:51.476 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:42:51.476 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:42:51.477 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:42:51.477 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-05-29:00:42:51:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[00:42:51] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.06857#011validation-error:0.06824\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:42:51.628 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO hook.py:423] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-05-29 00:42:51.632 ip-10-0-241-94.ap-southeast-2.compute.internal:7 INFO hook.py:486] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[00:42:51] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.06822#011validation-error:0.06864\u001b[0m\n",
      "\u001b[34m[00:42:51] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.06740#011validation-error:0.06917\u001b[0m\n",
      "\u001b[34m[00:42:51] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.06745#011validation-error:0.06917\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.06751#011validation-error:0.06839\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.06785#011validation-error:0.06799\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.06742#011validation-error:0.06842\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.06760#011validation-error:0.06774\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.06757#011validation-error:0.06744\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.06754#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.06696#011validation-error:0.06844\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.06698#011validation-error:0.06869\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 22 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.06699#011validation-error:0.06877\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.06689#011validation-error:0.06832\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.06695#011validation-error:0.06822\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.06667#011validation-error:0.06832\u001b[0m\n",
      "\u001b[34m[00:42:52] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.06672#011validation-error:0.06817\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 36 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.06657#011validation-error:0.06807\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.06657#011validation-error:0.06807\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.06667#011validation-error:0.06819\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.06650#011validation-error:0.06834\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.06630#011validation-error:0.06879\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.06617#011validation-error:0.06882\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.06613#011validation-error:0.06862\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.06610#011validation-error:0.06864\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.06610#011validation-error:0.06929\u001b[0m\n",
      "\u001b[34m[00:42:53] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.06607#011validation-error:0.06944\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.06610#011validation-error:0.06922\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.06607#011validation-error:0.06939\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.06607#011validation-error:0.06949\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.06622#011validation-error:0.06989\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.06612#011validation-error:0.07002\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.06605#011validation-error:0.06967\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.06599#011validation-error:0.06952\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.06597#011validation-error:0.06947\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.06589#011validation-error:0.06967\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.06611#011validation-error:0.06929\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.06593#011validation-error:0.06982\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.06589#011validation-error:0.06967\u001b[0m\n",
      "\u001b[34m[00:42:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.06594#011validation-error:0.06969\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.06577#011validation-error:0.06984\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.06582#011validation-error:0.06982\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.06562#011validation-error:0.06999\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 4 extra nodes, 22 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.06562#011validation-error:0.06999\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.06554#011validation-error:0.06987\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.06560#011validation-error:0.06947\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 24 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.06555#011validation-error:0.06957\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.06557#011validation-error:0.07034\u001b[0m\n",
      "\u001b[34m[00:42:55] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.06561#011validation-error:0.07037\u001b[0m\n",
      "\u001b[34m[00:42:56] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.06568#011validation-error:0.07027\u001b[0m\n",
      "\n",
      "2024-05-29 00:43:18 Uploading - Uploading generated training model\n",
      "2024-05-29 00:43:18 Completed - Training job completed\n",
      "Training seconds: 124\n",
      "Billable seconds: 124\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', region, version='1.2-2')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(default_bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker_session)\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth= 5,\n",
    "    eta= 0.2,\n",
    "    gamma= 4,\n",
    "    min_child_weight= 6,\n",
    "    subsample= 0.7,\n",
    "    objective= 'binary:logistic',\n",
    "    num_round= 50,\n",
    "    verbosity= 2\n",
    ")\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our ranking model, let's deploy it as a real-time endpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-05-29-00-43-39-427\n",
      "INFO:sagemaker:Creating endpoint-config with name recsys-rerank-model-05-29-00-34\n",
      "INFO:sagemaker:Creating endpoint with name recsys-rerank-model-05-29-00-34\n"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(\n",
    "    endpoint_name = ranking_model_endpoint_name,\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.m4.xlarge',\n",
    "    serializer = CSVSerializer(),\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recsys-rerank-model-05-29-00-34'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CF inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_rated_products_by_customer_state(customer_id, top_n):\n",
    "    # Sample some records to be used for inference\n",
    "    # Sample by top rated products in State\n",
    "    record = featurestore_runtime.get_record(FeatureGroupName=customers_feature_group_name,\n",
    "                                             RecordIdentifierValueAsString=customer_id,\n",
    "                                             FeatureNames=['state', 'is_married', 'age'])\n",
    "    # Parse through record features\n",
    "    other_customer_features = {}\n",
    "    for feature in record['Record']:\n",
    "        other_customer_features[feature['FeatureName']] = feature['ValueAsString']\n",
    "        \n",
    "    # Get state\n",
    "    state = other_customer_features['state']\n",
    "    # Filter DF by state\n",
    "    df_cf_features_by_state = df_cf_features[df_cf_features['state'] == state]\n",
    "    \n",
    "    # Get top rated products by customer's state\n",
    "    popular_items = df_cf_features_by_state.groupby([\"product_id\", \"product_name\"])['rating'].agg('mean').sort_values(ascending=False).reset_index()\n",
    "    for k, v in other_customer_features.items():\n",
    "        popular_items[k] = v\n",
    "    popular_items['customer_id'] = customer_id\n",
    "    top_n_popular_items = popular_items.iloc[0:top_n]\n",
    "    top_n_popular_items = top_n_popular_items[df_cf_features.columns]\n",
    "    del top_n_popular_items['rating']\n",
    "    return top_n_popular_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the cold-start problem (if a customer has yet to purchase any items), we'll fetch the top-rated products in a given customer's state. We'll then transform this data (like we did with the collaborative filtering model's training data), and use it at the time of inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'cf_inference_payload' (ndarray)\n",
      "Stored 'cf_inference_df' (DataFrame)\n",
      "date and time:  29/05/2024 00:44:47\n"
     ]
    }
   ],
   "source": [
    "customer_id = 'C3571'\n",
    "cf_inference_df = top_rated_products_by_customer_state(customer_id, 15)\n",
    "cf_inference_payload = transform_cf_data(df_cf_features, cf_inference_df).toarray()\n",
    "\n",
    "ps.add({'inference_customer_id': customer_id})\n",
    "\n",
    "# Save cf_inference_payload for next notebook\n",
    "%store cf_inference_payload\n",
    "%store cf_inference_df\n",
    "ps.store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to Workshop Studio and click on \"Next\"."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "interpreter": {
   "hash": "fea7262dfaa662dc7ea8f1b256cf975fd886d2f868152164ef15877318a1e322"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
