{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Realtime Recommendations\n",
    "\n",
    "Specify \"Python 3\" Kernel  and \"Data Science\" Image. Set the instance type as ml.t3.medium (default) for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "In this notebook, we will get personalized product recommendations using the Collaborative Filtering model and the Ranking model we deployed in notebook 2.\n",
    "\n",
    "We'll do this by:\n",
    "\n",
    "1. Using the deployed Collborative Filtering model which will take the payload that we cached in notebook 2 (to address the cold start problem) as input and generate candidate products based on the user-item interaction.\n",
    "2. Feeding these candidate products into our Ranking model along with click stream data from our `click stream` Feature Group. You'll see that the real-time click stream data will directly influence the ranking of the candidate products at the time of inference.\n",
    "\n",
    "<img src=\"./img/inference-arch.png\" alt=\"Inference arch\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import random\n",
    "from parameter_store import ParameterStore\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "featurestore_runtime = boto3.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "ps = ParameterStore(verbose=False)\n",
    "ps.set_namespace('feature-store-workshop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results= 'sagemaker-recsys-featurestore-workshop'\n",
    "prefix = 'recsys-feature-store'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load variables from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ps.read()\n",
    "customers_feature_group_name = parameters['customers_feature_group_name']\n",
    "products_feature_group_name = parameters['products_feature_group_name']\n",
    "orders_feature_group_name = parameters['orders_feature_group_name']\n",
    "click_stream_historical_feature_group_name = parameters['click_stream_historical_feature_group_name']\n",
    "click_stream_feature_group_name = parameters['click_stream_feature_group_name']\n",
    "\n",
    "customers_table = parameters['customers_table']\n",
    "products_table = parameters['products_table']\n",
    "orders_table = parameters['orders_table']\n",
    "click_stream_historical_table = parameters['click_stream_historical_table']\n",
    "click_stream_table = parameters['click_stream_table']\n",
    "\n",
    "train_data_location = parameters['train_data_location']\n",
    "test_data_location = parameters['test_data_location']\n",
    "\n",
    "cf_model_endpoint_name = parameters['cf_model_endpoint_name']\n",
    "ranking_model_endpoint_name = parameters['ranking_model_endpoint_name']\n",
    "\n",
    "customer_id = parameters['inference_customer_id']\n",
    "\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unranked recommended products from the Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Predictor` object from our collaborative filtering model endpoint (which we deployed in notebook 2) so that we can use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure model has finished deploying\n",
    "existing_endpoints = sagemaker_session.sagemaker_client.list_endpoints(NameContains=cf_model_endpoint_name, MaxResults=30)[\"Endpoints\"]\n",
    "while not existing_endpoints:\n",
    "    time.sleep(60)\n",
    "    existing_endpoints = sagemaker_session.sagemaker_client.list_endpoints(NameContains=cf_model_endpoint_name, MaxResults=30)[\"Endpoints\"]\n",
    "\n",
    "cf_model_predictor = sagemaker.predictor.Predictor(endpoint_name=cf_model_endpoint_name, \n",
    "                                                   sagemaker_session=sagemaker_session,\n",
    "                                                   serializer=FMSerializer(),\n",
    "                                                   deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in our cached data as input to the Collaborative Filtering model\n",
    "predictions = cf_model_predictor.predict(cf_inference_payload)['predictions']\n",
    "\n",
    "# Add those predictions to the input DataFrame\n",
    "predictions = [prediction[\"score\"] for prediction in predictions]\n",
    "cf_inference_df['predictions'] = predictions\n",
    "\n",
    "# Sort by predictions and take top 10\n",
    "cf_inference_df = cf_inference_df.sort_values(by='predictions', ascending=False).head(10).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output from our collaborative filtering model. These unranked products are recommended to the customer based on their purchase history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These products aren't personalized which is what we'll use the ranking model for. The ranking model will take into account the customer's current behavior on the website which will influence the ranking of the recommended products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank the recommended products using the Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Predictor` object from our ranking model endpoint (which we deployed in notebook 2) so that we can use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure model has finished deploying\n",
    "existing_endpoints = sagemaker_session.sagemaker_client.list_endpoints(NameContains=ranking_model_endpoint_name, MaxResults=30)[\"Endpoints\"]\n",
    "while not existing_endpoints:\n",
    "    time.sleep(60)\n",
    "    existing_endpoints = sagemaker_session.sagemaker_client.list_endpoints(NameContains=ranking_model_endpoint_name, MaxResults=30)[\"Endpoints\"]\n",
    "\n",
    "ranking_model_predictor = sagemaker.predictor.Predictor(endpoint_name=ranking_model_endpoint_name, \n",
    "                                                        sagemaker_session=sagemaker_session,\n",
    "                                                        serializer = CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct the input for the ranking model, we need to one-hot encode product categories as we did in training. Ideally, these one-hot encoded products would be cached somewhere (perhaps in SageMaker Feature Store or another AWS service) but we're keeping it simple for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select product_category\n",
    "from \"{products_table}\"\n",
    "order by product_category\n",
    "'''\n",
    "product_categories_df, query = query_offline_store(products_feature_group_name, query,\n",
    "                                                   sagemaker_session)\n",
    "one_hot_cat_features = product_categories_df.product_category.unique()\n",
    "\n",
    "df_one_hot_cat_features = pd.DataFrame(one_hot_cat_features)\n",
    "df_one_hot_cat_features.columns = ['product_category']\n",
    "\n",
    "df_one_hot_cat_features = pd.concat([df_one_hot_cat_features, pd.get_dummies(df_one_hot_cat_features['product_category'], prefix='cat')],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to take the output from the collaborative filtering model and join it with the one-hot encoded product categories _**AND**_ the real-time click stream data from our `click stream` Feature Group, as this data will influence the ranking of recommended products. You can imagine the ranking inputs like so:\n",
    "\n",
    "<img src=\"./img/vector-input-for-ranking.png\" alt=\"Ranking input\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "We'll use this function in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking_model_input_data(df, df_one_hot_cat_features):\n",
    "    product_category_list = []\n",
    "    product_health_index_list = []\n",
    "    \n",
    "    customer_id = df.iloc[0]['customer_id']\n",
    "    # Get customer features from customers_feature_group_name\n",
    "    customer_record = featurestore_runtime.get_record(FeatureGroupName=customers_feature_group_name,\n",
    "                                                      RecordIdentifierValueAsString=customer_id,\n",
    "                                                      FeatureNames=['customer_health_index'])\n",
    "    \n",
    "    customer_health_index = customer_record['Record'][0]['ValueAsString']\n",
    "    \n",
    "    # Get product features (instead of looping, you can optionally use\n",
    "    # the `batch_get_record` Feature Store API)\n",
    "    for index, row_tuple in df.iterrows():\n",
    "        \n",
    "        product_id = row_tuple['product_id']\n",
    "        \n",
    "        # Get product features from products_feature_group_name\n",
    "        product_record = featurestore_runtime.get_record(FeatureGroupName=products_feature_group_name,\n",
    "                                                         RecordIdentifierValueAsString=product_id,\n",
    "                                                         FeatureNames=['product_category',\n",
    "                                                                       'product_health_index'])\n",
    "        \n",
    "        product_category = product_record['Record'][0]['ValueAsString']\n",
    "        product_health_index = product_record['Record'][1]['ValueAsString']\n",
    "        \n",
    "        product_category_list.append(product_category)\n",
    "        product_health_index_list.append(product_health_index)\n",
    "\n",
    "        \n",
    "\n",
    "    # Get click stream features from customers_click_stream_feature_group_name\n",
    "    click_stream_record = featurestore_runtime.get_record(FeatureGroupName=click_stream_feature_group_name,\n",
    "                                                          RecordIdentifierValueAsString=customer_id,\n",
    "                                                          FeatureNames=['sum_activity_weight_last_2m',\n",
    "                                                                  'avg_product_health_index_last_2m'])\n",
    "    \n",
    "    # Calculate healthy_activity_last_2m as this will influence ranking as well\n",
    "    sum_activity_weight_last_2m = click_stream_record['Record'][0]['ValueAsString']\n",
    "    avg_product_health_index_last_2m = click_stream_record['Record'][1]['ValueAsString']\n",
    "    healthy_activity_last_2m = int(sum_activity_weight_last_2m) * float(avg_product_health_index_last_2m)\n",
    "\n",
    "    data = {'healthy_activity_last_2m': healthy_activity_last_2m,\n",
    "            'product_health_index': product_health_index_list,\n",
    "            'customer_health_index': customer_health_index,\n",
    "            'product_category': product_category_list}\n",
    "    \n",
    "    ranking_inference_df = pd.DataFrame(data)\n",
    "    ranking_inference_df = ranking_inference_df.merge(df_one_hot_cat_features, on='product_category',\n",
    "                                                      how='left')\n",
    "    del ranking_inference_df['product_category']\n",
    "\n",
    "    return ranking_inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time personalized product recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally put everything together by calling the function we created above to get real-time personalized product recommendations using data that's being streamed to SageMaker Feature Store to influence ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we already have our unranked recommended products for our collaborative filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to rank those products recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct input data for the ranking model\n",
    "ranking_inference_df = get_ranking_model_input_data(cf_inference_df, df_one_hot_cat_features)\n",
    "\n",
    "# Get our ranked product recommendations and attach the predictions to the model input\n",
    "ranking_inference_df['propensity_to_buy'] = ranking_model_predictor.predict(ranking_inference_df.to_numpy()).decode('utf-8').split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our personalized ranked recommendations, let's see what the top 5 recommended products are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the data back together for inspection\n",
    "personalized_recommendations = pd.concat([cf_inference_df[['customer_id', 'product_id', 'product_name']],\n",
    "                                          ranking_inference_df[['propensity_to_buy']]], axis=1)\n",
    "\n",
    "# And sort by propensity to buy\n",
    "personalized_recommendations.sort_values(by='propensity_to_buy', ascending=False)[['product_id','product_name']].reset_index(drop=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Personalized recommendations </strong>\n",
    "Note how the ranking changed based on the customer's last 2 minutes of activity on the website.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've officially built a recommendation engine system leveraging SageMaker Feature Store as a way to both train the recommendation engine models and influence recommendations in real-time! ðŸŽ‰ ðŸ’ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional)\n",
    "\n",
    "Now you've seen real-time recommendations for a customer interacting with unhealthy products, you can repeat this experiment to simulate healthy product interactions by ingesting new data to the stream. If you'd like to do this, follow the below steps:\n",
    "\n",
    "1. Go to notebook 3, navigate to the last section.\n",
    "2. Replace `put_records_in_kinesis_stream(inference_customer_id, 0.1, 0.3)` with `put_records_in_kinesis_stream(inference_customer_id, 0.7, 0.9)`.\n",
    "3. Wait for the data to be ingested to the Kinesis Data Stream.\n",
    "4. Re-run the \"Real-time personalized recommendation\" section in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to Workshop Studio and click on \"Next\"."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "fea7262dfaa662dc7ea8f1b256cf975fd886d2f868152164ef15877318a1e322"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
